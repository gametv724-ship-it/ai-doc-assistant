from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
import PyPDF2
from docx import Document
import openpyxl
import uuid
import os

class DocumentRAG:
    def __init__(self, use_docker=True):
        print("üîÑ –ó–∞–≥—Ä—É–∂–∞—é embeddings –º–æ–¥–µ–ª—å...")
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Qdrant
        self.use_docker = False  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–∞–º—è—Ç—å
        
        if use_docker:
            try:
                # –ü—Ä–æ–±—É–µ–º –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Docker
                test_client = QdrantClient(host="localhost", port=6333, timeout=2)
                test_client.get_collections()  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
                self.qdrant = test_client
                self.use_docker = True
                print("‚úÖ –ü–æ–¥–∫–ª—é—á–∏–ª—Å—è –∫ Qdrant (Docker)")
            except Exception as e:
                print(f"‚ö†Ô∏è Docker –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ({str(e)[:50]}), –∏—Å–ø–æ–ª—å–∑—É—é –ø–∞–º—è—Ç—å")
                self.qdrant = QdrantClient(":memory:")
        else:
            self.qdrant = QdrantClient(":memory:")
            print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é Qdrant –≤ –ø–∞–º—è—Ç–∏")
        
        self.collection_name = "documents"
        self._create_collection()
    
    def _create_collection(self):
        """–°–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
        try:
            collections = self.qdrant.get_collections().collections
            collection_exists = any(c.name == self.collection_name for c in collections)
            
            if not collection_exists:
                self.qdrant.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(size=384, distance=Distance.COSINE)
                )
                print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è '{self.collection_name}'")
            else:
                print(f"‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è '{self.collection_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        except Exception as e:
            # –ï—Å–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –Ω–µ—Ç - —Å–æ–∑–¥–∞—ë–º
            self.qdrant.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(size=384, distance=Distance.COSINE)
            )
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è '{self.collection_name}'")
    
    def load_pdf(self, file_path):
        """–ß–∏—Ç–∞–µ–º PDF"""
        text = ""
        with open(file_path, 'rb') as f:
            reader = PyPDF2.PdfReader(f)
            for page in reader.pages:
                extracted = page.extract_text()
                if extracted:
                    text += extracted + "\n"
        return text
    
    def load_docx(self, file_path):
        """–ß–∏—Ç–∞–µ–º Word"""
        doc = Document(file_path)
        return "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
    
    def load_xlsx(self, file_path):
        """–ß–∏—Ç–∞–µ–º Excel"""
        wb = openpyxl.load_workbook(file_path)
        text = ""
        for sheet in wb.worksheets:
            text += f"\n=== {sheet.title} ===\n"
            for row in sheet.iter_rows(values_only=True):
                row_text = " | ".join([str(cell) if cell else "" for cell in row])
                if row_text.strip():
                    text += row_text + "\n"
        return text
    
    def chunk_text(self, text, chunk_size=500, overlap=50):
        """–†–µ–∂–µ–º –Ω–∞ —á–∞–Ω–∫–∏"""
        words = text.split()
        chunks = []
        for i in range(0, len(words), chunk_size - overlap):
            chunk = " ".join(words[i:i + chunk_size])
            if chunk.strip():
                chunks.append(chunk)
        return chunks
    
    def add_document(self, file_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î"""
        ext = os.path.splitext(file_path)[1].lower()
        
        try:
            if ext == '.pdf':
                text = self.load_pdf(file_path)
            elif ext == '.docx':
                text = self.load_docx(file_path)
            elif ext in ['.xlsx', '.xls']:
                text = self.load_xlsx(file_path)
            else:
                return f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {ext}"
            
            if not text.strip():
                return "‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç"
            
            chunks = self.chunk_text(text)
            
            if not chunks:
                return "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —á–∞–Ω–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"
            
            print(f"üìù –°–æ–∑–¥–∞—é embeddings –¥–ª—è {len(chunks)} —á–∞–Ω–∫–æ–≤...")
            embeddings = self.embedder.encode(chunks, show_progress_bar=True)
            
            points = [
                PointStruct(
                    id=str(uuid.uuid4()),
                    vector=embedding.tolist(),
                    payload={
                        "text": chunk, 
                        "source": os.path.basename(file_path)
                    }
                )
                for chunk, embedding in zip(chunks, embeddings)
            ]
            
            self.qdrant.upsert(
                collection_name=self.collection_name,
                points=points
            )
            
            return f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ {os.path.basename(file_path)}"
            
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}"
    
    def search(self, query, top_k=3):
        """–ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —á–∞–Ω–∫–∏"""
        try:
            query_vector = self.embedder.encode(query).tolist()
            
            results = self.qdrant.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                limit=top_k
            )
            
            return [
                {
                    "text": hit.payload["text"],
                    "score": hit.score,
                    "source": hit.payload["source"]
                }
                for hit in results
            ]
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    def answer_question(self, question, use_llm=False, groq_api_key=None):
        """–ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å"""
        context_chunks = self.search(question, top_k=3)
        
        if not context_chunks:
            return {
                "answer": "‚ùå –ù–µ –Ω–∞—à—ë–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ. –ü–æ–ø—Ä–æ–±—É–π –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å–Ω–∞—á–∞–ª–∞.",
                "sources": []
            }
        
        context = "\n\n".join([chunk["text"] for chunk in context_chunks])
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å Groq API ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º LLM
        if use_llm and groq_api_key and groq_api_key.strip():
            try:
                from groq import Groq
                
                # –û—á–∏—â–∞–µ–º –∫–ª—é—á –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
                api_key_clean = groq_api_key.strip()
                
                client = Groq(api_key=api_key_clean)
                
                response = client.chat.completions.create(
                    model="llama-3.1-8b-instant",
                    messages=[
                        {
                            "role": "system", 
                            "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
                        },
                        {
                            "role": "user", 
                            "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞:\n{context}\n\n–í–æ–ø—Ä–æ—Å: {question}\n\n–û—Ç–≤–µ—Ç:"
                        }
                    ],
                    temperature=0.3,
                    max_tokens=500
                )
                
                answer = response.choices[0].message.content
                
            except Exception as e:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç –±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ—à–∏–±–∫–∏
                answer = f"üìÑ –ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n\n{context}"
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Groq API: {str(e)}")
        else:
            # –ë–µ–∑ LLM ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–Ω—ë–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            answer = f"üìÑ –ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n\n{context}"
        
        return {
            "answer": answer,
            "sources": context_chunks
        }
